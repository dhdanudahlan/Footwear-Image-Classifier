{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZj_eV-7Vu3S",
        "outputId": "d57bd9ff-372d-487e-d0f2-75a9e5c9924e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.12.0\n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "Author:\n",
        "Nama: Dimas Humayun Danu Dahlan\n",
        "Email: dhdanudahlan@gmail.com\n",
        "Username : dhdanudahlan\n",
        "Institution: Sriwijaya University\n",
        "'''\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLCQCfDg7N4V",
        "outputId": "4ea31913-4bee-4506-f8f8-a7b0c31e59c7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.9/dist-packages (1.5.13)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.9/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from kaggle) (4.65.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.27.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.9/dist-packages (from kaggle) (2022.12.7)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.9/dist-packages (from kaggle) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.9/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->kaggle) (3.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import all all the necessary module\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Input\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import os, shutil, zipfile\n",
        "import random, time"
      ],
      "metadata": {
        "id": "k_EcTmPM0HtR"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "QdawU2dl-VZs"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download dataset automatically and saved it in temp dir as a zip file\n",
        "!kaggle datasets download -d hasibalmuzdadid/shoe-vs-sandal-vs-boot-dataset-15k-images -p /content/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xECHJJi9Wc2b",
        "outputId": "2bb5ae85-24ad-4e8f-98fe-df509f1aa4ef"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading shoe-vs-sandal-vs-boot-dataset-15k-images.zip to /content/dataset\n",
            " 96% 45.0M/47.0M [00:00<00:00, 156MB/s]\n",
            "100% 47.0M/47.0M [00:00<00:00, 143MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract dataset from temp directory to content directory\n",
        "\n",
        "local_zip = '/content/dataset/shoe-vs-sandal-vs-boot-dataset-15k-images.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('dataset_1')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "cjj460u9Wue2"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Preprocessing Data [Dicoding]\n",
        "\n",
        "# Create folders to stored the separated dataset\n",
        "\n",
        "base_dir = 'dataset_1'\n",
        "data_dir = ['Boot', 'Sandal', 'Shoe']\n",
        "for i in data_dir:\n",
        "  if os.path.exists(base_dir+ '/Shoe vs Sandal vs Boot Dataset/'+i):\n",
        "    if not os.path.exists(base_dir+ '/' +i):\n",
        "      shutil.move(base_dir+ '/Shoe vs Sandal vs Boot Dataset/'+i, base_dir)\n",
        "if os.path.exists(base_dir+ '/Shoe vs Sandal vs Boot Dataset'):\n",
        "  shutil.rmtree(base_dir+ '/Shoe vs Sandal vs Boot Dataset')\n",
        "\n",
        "TRAINING_DIR = \"dataset_1/train\"\n",
        "VALIDATION_DIR = \"dataset_1/test\"\n",
        "\n",
        "train_dir = TRAINING_DIR\n",
        "validation_dir = VALIDATION_DIR\n",
        "\n",
        "\n",
        "if not os.path.exists(TRAINING_DIR):\n",
        "  os.makedirs(TRAINING_DIR)\n",
        "if not os.path.exists(VALIDATION_DIR):\n",
        "  os.makedirs(VALIDATION_DIR)\n",
        "\n",
        "# Separate dataset into train data and validation data\n",
        "for i in data_dir:\n",
        "  src = base_dir + '/' + i\n",
        "  allFileNames = os.listdir(src)\n",
        "  np.random.shuffle(allFileNames)\n",
        "  train_fileNames, val_fileNames = np.split(np.array(allFileNames), \n",
        "                                            [int(len(allFileNames)*0.8)])\n",
        "\n",
        "  train_fileNames = [src +'/'+ name for name in train_fileNames.tolist()]\n",
        "  val_fileNames = [src +'/'+ name for name in val_fileNames.tolist()]\n",
        "\n",
        "  # print('Total images: ', len(allFileNames))\n",
        "  # print('Training: ', len(train_fileNames))\n",
        "  # print('Validation: ', len(val_fileNames))\n",
        "  \n",
        "  if not os.path.exists(train_dir + '/' + i):\n",
        "    os.makedirs(train_dir + '/' + i)\n",
        "  if not os.path.exists(validation_dir + '/' + i):\n",
        "    os.makedirs(validation_dir + '/' + i)\n",
        "\n",
        "  for name in train_fileNames:\n",
        "    # print(\"=======================\")\n",
        "    # print(name)\n",
        "    # print('to')\n",
        "    # print(train_dir + '/' + i)\n",
        "    shutil.copy(name, train_dir + '/' + i)\n",
        "\n",
        "  for name in val_fileNames:\n",
        "    # print(\"------------------------\")\n",
        "    # print(name)\n",
        "    # print('to')\n",
        "    # print(validation_dir + '/' + i)\n",
        "    shutil.copy(name, validation_dir + '/' + i)\n"
      ],
      "metadata": {
        "id": "ceQPB8llWxhg"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(train_dir))\n",
        "print('Training Data: ' + \n",
        "    str(\n",
        "      len(os.listdir(train_dir + '/' + data_dir[0]))+\n",
        "      len(os.listdir(train_dir + '/' + data_dir[1]))+\n",
        "      len(os.listdir(train_dir + '/' + data_dir[2]))\n",
        "    ))\n",
        "\n",
        "print(os.listdir(validation_dir))\n",
        "print('Validation Data: ' + \n",
        "    str(\n",
        "      len(os.listdir(validation_dir + '/' + data_dir[0]))+\n",
        "      len(os.listdir(validation_dir + '/' + data_dir[1]))+\n",
        "      len(os.listdir(validation_dir + '/' + data_dir[2]))\n",
        "    ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMsstcgDy8pe",
        "outputId": "1939b0c4-d7be-40b4-e317-2fe3811f69ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Sandal', 'Boot', 'Shoe']\n",
            "Training Data: 12000\n",
            "['Sandal', 'Boot', 'Shoe']\n",
            "Validation Data: 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Declare the images augmentation\n",
        "\n",
        " \n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    fill_mode = 'nearest',\n",
        "    validation_split=0.2\n",
        "    )\n",
        " \n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale=1./255\n",
        "    )"
      ],
      "metadata": {
        "id": "l-I0FkGtzMVc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate train and validation data\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (150,150),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 32,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCF6_2-7zWtH",
        "outputId": "f6b860b8-673c-42a5-f9f1-e474b30a04f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 12000 images belonging to 3 classes.\n",
            "Found 3000 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the model\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    tf.keras.layers.Flatten(),  # Flatten the results to feed into a DNN\n",
        "    \n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "HJZHbx-m8dY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.summary()"
      ],
      "metadata": {
        "id": "8bXRPIuS87Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "\n",
        "int_lr = 1e-4\n",
        "num_epochs = 100\n",
        "optimizer = tf.optimizers.Adam(lr=int_lr)\n",
        "model.compile(\n",
        "    optimizer = optimizer,\n",
        "    loss = 'categorical_crossentropy',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "SRLwJ95h9CaI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4753dc53-d1e2-4008-fd93-5b966d7f3560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback that will be executed once the accuracy reach 90%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.80):\n",
        "      if(logs.get('val_accuracy')>0.98):\n",
        "        print(\"\\nAccuracy is >98%!\")\n",
        "        self.model.stop_training = True\n",
        "callback = myCallback()"
      ],
      "metadata": {
        "id": "wTT9kTBF5Uku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set timer and train model\n",
        "start_time = time.time()\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs = num_epochs,\n",
        "    steps_per_epoch = 20,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = 5,\n",
        "    verbose = 2,\n",
        "    callbacks=[callback]\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "final_time = end_time - start_time\n",
        "print('Timer: ', final_time / 60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPvzyKl45ZQs",
        "outputId": "286ca1d2-856c-4877-ec29-f099df5474f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "20/20 - 51s - loss: 1.0993 - accuracy: 0.3656 - val_loss: 1.0790 - val_accuracy: 0.3812 - 51s/epoch - 3s/step\n",
            "Epoch 2/100\n",
            "20/20 - 37s - loss: 1.0736 - accuracy: 0.3766 - val_loss: 1.0498 - val_accuracy: 0.3625 - 37s/epoch - 2s/step\n",
            "Epoch 3/100\n",
            "20/20 - 39s - loss: 1.0000 - accuracy: 0.4875 - val_loss: 0.9674 - val_accuracy: 0.5375 - 39s/epoch - 2s/step\n",
            "Epoch 4/100\n",
            "20/20 - 37s - loss: 0.9637 - accuracy: 0.5406 - val_loss: 0.7456 - val_accuracy: 0.6750 - 37s/epoch - 2s/step\n",
            "Epoch 5/100\n",
            "20/20 - 37s - loss: 0.9276 - accuracy: 0.5609 - val_loss: 0.9021 - val_accuracy: 0.5750 - 37s/epoch - 2s/step\n",
            "Epoch 6/100\n",
            "20/20 - 40s - loss: 0.9672 - accuracy: 0.5000 - val_loss: 0.8736 - val_accuracy: 0.7188 - 40s/epoch - 2s/step\n",
            "Epoch 7/100\n",
            "20/20 - 37s - loss: 0.9089 - accuracy: 0.5578 - val_loss: 0.8837 - val_accuracy: 0.5750 - 37s/epoch - 2s/step\n",
            "Epoch 8/100\n",
            "20/20 - 37s - loss: 0.9002 - accuracy: 0.5766 - val_loss: 0.7249 - val_accuracy: 0.6562 - 37s/epoch - 2s/step\n",
            "Epoch 9/100\n",
            "20/20 - 37s - loss: 0.8937 - accuracy: 0.5688 - val_loss: 0.7583 - val_accuracy: 0.6500 - 37s/epoch - 2s/step\n",
            "Epoch 10/100\n",
            "20/20 - 37s - loss: 0.8606 - accuracy: 0.5797 - val_loss: 0.7348 - val_accuracy: 0.6438 - 37s/epoch - 2s/step\n",
            "Epoch 11/100\n",
            "20/20 - 37s - loss: 0.8253 - accuracy: 0.6062 - val_loss: 0.6975 - val_accuracy: 0.6500 - 37s/epoch - 2s/step\n",
            "Epoch 12/100\n",
            "20/20 - 37s - loss: 0.8194 - accuracy: 0.6234 - val_loss: 0.8184 - val_accuracy: 0.6562 - 37s/epoch - 2s/step\n",
            "Epoch 13/100\n",
            "20/20 - 42s - loss: 0.8176 - accuracy: 0.6219 - val_loss: 0.7403 - val_accuracy: 0.6313 - 42s/epoch - 2s/step\n",
            "Epoch 14/100\n",
            "20/20 - 37s - loss: 0.7991 - accuracy: 0.6062 - val_loss: 0.6909 - val_accuracy: 0.6938 - 37s/epoch - 2s/step\n",
            "Epoch 15/100\n",
            "20/20 - 37s - loss: 0.7645 - accuracy: 0.6531 - val_loss: 0.6949 - val_accuracy: 0.6875 - 37s/epoch - 2s/step\n",
            "Epoch 16/100\n",
            "20/20 - 37s - loss: 0.8277 - accuracy: 0.6141 - val_loss: 0.6119 - val_accuracy: 0.7563 - 37s/epoch - 2s/step\n",
            "Epoch 17/100\n",
            "20/20 - 37s - loss: 0.7501 - accuracy: 0.6625 - val_loss: 0.6385 - val_accuracy: 0.7375 - 37s/epoch - 2s/step\n",
            "Epoch 18/100\n",
            "20/20 - 37s - loss: 0.7204 - accuracy: 0.6594 - val_loss: 0.6185 - val_accuracy: 0.7250 - 37s/epoch - 2s/step\n",
            "Epoch 19/100\n",
            "20/20 - 37s - loss: 0.7201 - accuracy: 0.6969 - val_loss: 0.6483 - val_accuracy: 0.7063 - 37s/epoch - 2s/step\n",
            "Epoch 20/100\n",
            "20/20 - 37s - loss: 0.7136 - accuracy: 0.6844 - val_loss: 0.6660 - val_accuracy: 0.7125 - 37s/epoch - 2s/step\n",
            "Epoch 21/100\n",
            "20/20 - 40s - loss: 0.7260 - accuracy: 0.6750 - val_loss: 0.7167 - val_accuracy: 0.6812 - 40s/epoch - 2s/step\n",
            "Epoch 22/100\n",
            "20/20 - 37s - loss: 0.7027 - accuracy: 0.6922 - val_loss: 0.5816 - val_accuracy: 0.7188 - 37s/epoch - 2s/step\n",
            "Epoch 23/100\n",
            "20/20 - 37s - loss: 0.7188 - accuracy: 0.6625 - val_loss: 0.5328 - val_accuracy: 0.7625 - 37s/epoch - 2s/step\n",
            "Epoch 24/100\n",
            "20/20 - 37s - loss: 0.7201 - accuracy: 0.6687 - val_loss: 0.5513 - val_accuracy: 0.7812 - 37s/epoch - 2s/step\n",
            "Epoch 25/100\n",
            "20/20 - 37s - loss: 0.6708 - accuracy: 0.6984 - val_loss: 0.6470 - val_accuracy: 0.6687 - 37s/epoch - 2s/step\n",
            "Epoch 26/100\n",
            "20/20 - 37s - loss: 0.6935 - accuracy: 0.6766 - val_loss: 0.5246 - val_accuracy: 0.7875 - 37s/epoch - 2s/step\n",
            "Epoch 27/100\n",
            "20/20 - 40s - loss: 0.6126 - accuracy: 0.7297 - val_loss: 0.5803 - val_accuracy: 0.7125 - 40s/epoch - 2s/step\n",
            "Epoch 28/100\n",
            "20/20 - 37s - loss: 0.6415 - accuracy: 0.7234 - val_loss: 0.4598 - val_accuracy: 0.7875 - 37s/epoch - 2s/step\n",
            "Epoch 29/100\n",
            "20/20 - 37s - loss: 0.6216 - accuracy: 0.7094 - val_loss: 0.5330 - val_accuracy: 0.7125 - 37s/epoch - 2s/step\n",
            "Epoch 30/100\n",
            "20/20 - 37s - loss: 0.6926 - accuracy: 0.6750 - val_loss: 0.4941 - val_accuracy: 0.7750 - 37s/epoch - 2s/step\n",
            "Epoch 31/100\n",
            "20/20 - 37s - loss: 0.6896 - accuracy: 0.6938 - val_loss: 0.5085 - val_accuracy: 0.7625 - 37s/epoch - 2s/step\n",
            "Epoch 32/100\n",
            "20/20 - 37s - loss: 0.6348 - accuracy: 0.7016 - val_loss: 0.5252 - val_accuracy: 0.8062 - 37s/epoch - 2s/step\n",
            "Epoch 33/100\n",
            "20/20 - 37s - loss: 0.6046 - accuracy: 0.7312 - val_loss: 0.4559 - val_accuracy: 0.8250 - 37s/epoch - 2s/step\n",
            "Epoch 34/100\n",
            "20/20 - 37s - loss: 0.6230 - accuracy: 0.7125 - val_loss: 0.4647 - val_accuracy: 0.7812 - 37s/epoch - 2s/step\n",
            "Epoch 35/100\n",
            "20/20 - 37s - loss: 0.6024 - accuracy: 0.7344 - val_loss: 0.4834 - val_accuracy: 0.8062 - 37s/epoch - 2s/step\n",
            "Epoch 36/100\n",
            "20/20 - 37s - loss: 0.6023 - accuracy: 0.7281 - val_loss: 0.5218 - val_accuracy: 0.8000 - 37s/epoch - 2s/step\n",
            "Epoch 37/100\n",
            "20/20 - 37s - loss: 0.6009 - accuracy: 0.7312 - val_loss: 0.5735 - val_accuracy: 0.6875 - 37s/epoch - 2s/step\n",
            "Epoch 38/100\n",
            "20/20 - 37s - loss: 0.5814 - accuracy: 0.7469 - val_loss: 0.5175 - val_accuracy: 0.7688 - 37s/epoch - 2s/step\n",
            "Epoch 39/100\n",
            "20/20 - 37s - loss: 0.5643 - accuracy: 0.7609 - val_loss: 0.6787 - val_accuracy: 0.6750 - 37s/epoch - 2s/step\n",
            "Epoch 40/100\n",
            "20/20 - 39s - loss: 0.6158 - accuracy: 0.7203 - val_loss: 0.5722 - val_accuracy: 0.7312 - 39s/epoch - 2s/step\n",
            "Epoch 41/100\n",
            "20/20 - 37s - loss: 0.5596 - accuracy: 0.7469 - val_loss: 0.4325 - val_accuracy: 0.8313 - 37s/epoch - 2s/step\n",
            "Epoch 42/100\n",
            "20/20 - 41s - loss: 0.5408 - accuracy: 0.7547 - val_loss: 0.4393 - val_accuracy: 0.7937 - 41s/epoch - 2s/step\n",
            "Epoch 43/100\n",
            "20/20 - 37s - loss: 0.5911 - accuracy: 0.7359 - val_loss: 0.3814 - val_accuracy: 0.8813 - 37s/epoch - 2s/step\n",
            "Epoch 44/100\n",
            "20/20 - 37s - loss: 0.5600 - accuracy: 0.7563 - val_loss: 0.4385 - val_accuracy: 0.8313 - 37s/epoch - 2s/step\n",
            "Epoch 45/100\n",
            "20/20 - 37s - loss: 0.5667 - accuracy: 0.7437 - val_loss: 0.5566 - val_accuracy: 0.7625 - 37s/epoch - 2s/step\n",
            "Epoch 46/100\n",
            "20/20 - 37s - loss: 0.5527 - accuracy: 0.7719 - val_loss: 0.3457 - val_accuracy: 0.8562 - 37s/epoch - 2s/step\n",
            "Epoch 47/100\n",
            "20/20 - 37s - loss: 0.5399 - accuracy: 0.7875 - val_loss: 0.4688 - val_accuracy: 0.7750 - 37s/epoch - 2s/step\n",
            "Epoch 48/100\n",
            "20/20 - 37s - loss: 0.5307 - accuracy: 0.7703 - val_loss: 0.4368 - val_accuracy: 0.8313 - 37s/epoch - 2s/step\n",
            "Epoch 49/100\n",
            "20/20 - 40s - loss: 0.5760 - accuracy: 0.7422 - val_loss: 0.4200 - val_accuracy: 0.8438 - 40s/epoch - 2s/step\n",
            "Epoch 50/100\n",
            "20/20 - 37s - loss: 0.5729 - accuracy: 0.7594 - val_loss: 0.5053 - val_accuracy: 0.7875 - 37s/epoch - 2s/step\n",
            "Epoch 51/100\n",
            "20/20 - 37s - loss: 0.5673 - accuracy: 0.7531 - val_loss: 0.5353 - val_accuracy: 0.7812 - 37s/epoch - 2s/step\n",
            "Epoch 52/100\n",
            "20/20 - 37s - loss: 0.5776 - accuracy: 0.7344 - val_loss: 0.4495 - val_accuracy: 0.7937 - 37s/epoch - 2s/step\n",
            "Epoch 53/100\n",
            "20/20 - 37s - loss: 0.5334 - accuracy: 0.7812 - val_loss: 0.3396 - val_accuracy: 0.8375 - 37s/epoch - 2s/step\n",
            "Epoch 54/100\n",
            "20/20 - 37s - loss: 0.5343 - accuracy: 0.7531 - val_loss: 0.4285 - val_accuracy: 0.8562 - 37s/epoch - 2s/step\n",
            "Epoch 55/100\n",
            "20/20 - 37s - loss: 0.5175 - accuracy: 0.7781 - val_loss: 0.3104 - val_accuracy: 0.8938 - 37s/epoch - 2s/step\n",
            "Epoch 56/100\n",
            "20/20 - 37s - loss: 0.5084 - accuracy: 0.7719 - val_loss: 0.3870 - val_accuracy: 0.8313 - 37s/epoch - 2s/step\n",
            "Epoch 57/100\n",
            "20/20 - 40s - loss: 0.5087 - accuracy: 0.7891 - val_loss: 0.4455 - val_accuracy: 0.8375 - 40s/epoch - 2s/step\n",
            "Epoch 58/100\n",
            "20/20 - 37s - loss: 0.5726 - accuracy: 0.7547 - val_loss: 0.4671 - val_accuracy: 0.7812 - 37s/epoch - 2s/step\n",
            "Epoch 59/100\n",
            "20/20 - 37s - loss: 0.4803 - accuracy: 0.8078 - val_loss: 0.4757 - val_accuracy: 0.7688 - 37s/epoch - 2s/step\n",
            "Epoch 60/100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate accuracy\n",
        "train_loss, train_acc = model.evaluate(train_generator)\n",
        "val_loss, val_acc = model.evaluate(validation_generator)\n",
        "\n",
        "print('\\nTrain accuracy: %.2f%%' % (train_acc * 100))\n",
        "print('\\nValidation accuracy: %.2f%%' % (val_acc * 100))"
      ],
      "metadata": {
        "id": "ms8R7XLhzs0u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iQ7Tv1s5w0tS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15, 5))\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W35f_3l9zv0U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Testing\n",
        "# Load a new image as a test sample and predict it\n",
        "%matplotlib inline\n",
        "uploaded_dir = random.choice(os.listdir(validation_dir))\n",
        "uploaded_name = random.choice(os.listdir(validation_dir + '/' + uploaded_dir))\n",
        "print(uploaded_name)\n",
        "# uploaded = files.upload()\n",
        "\n",
        "\n",
        "# preprocess and predict the image\n",
        "\n",
        "path = validation_dir + '/' + uploaded_dir + '/' + uploaded_name\n",
        "print(path)\n",
        "img = image.load_img(path, target_size=(150,150))\n",
        "\n",
        "imgplot = plt.imshow(img)\n",
        "x = image.img_to_array(img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "images = np.vstack([x])\n",
        "\n",
        "\n",
        "classes = model.predict(images, batch_size=10)\n",
        "if classes[0,0]!=0:\n",
        "  print('Boot')\n",
        "elif classes[0,1]!=0:\n",
        "  print('Sandal')\n",
        "else:\n",
        "  print('Shoe')"
      ],
      "metadata": {
        "id": "zfnr84BxzzM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model Converter\n",
        "# Save model using format SavedMode\n",
        "export_dir = 'saved_model/'\n",
        "tf.saved_model.save(model, export_dir)"
      ],
      "metadata": {
        "id": "f8X_sM38z0cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "converter = tf.lite.TFLiteConverter.from_saved_model(export_dir)\n",
        "tflite_model = converter.convert()"
      ],
      "metadata": {
        "id": "vsPtMeJfz1Ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tflite_model_file = pathlib.Path('vegs.tflite')\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "metadata": {
        "id": "z48zvldqz1kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "IR8wM2uhwcfo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OlZgO0iFwjO3"
      }
    }
  ]
}